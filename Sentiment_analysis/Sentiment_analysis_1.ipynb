{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b90806b",
   "metadata": {},
   "source": [
    "<font size=6> Word2Vec、Tf-Idf </font>\n",
    "\n",
    "<font size=3> \n",
    " 利用\n",
    " <font size=3 color=orange> Word2Vec、Tf-Idf </font>\n",
    " 萃取評論向量後，輸入\n",
    " <font size=3 color=orange> 隨機森林 </font>\n",
    " 以預測餐廳評分 (0, 1) </font> <br/>\n",
    "<font size=3> 評分為 1 ~ 5，將 4 以上的評分轉為 1，其餘轉為0 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58059b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocess\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "my_col = ['stars', 'text']\n",
    "data = pd.read_csv('yelp.csv', usecols=my_col)\n",
    "data['stars'] = data['stars'].apply(lambda x : 0 if x < 4 else 1)\n",
    "# data_Y = np.where(data['stars']>=4, 1, 0 )\n",
    "data['text'] = data['text'].str.lower()\n",
    "text_list = []\n",
    "for sentence in data['text']:\n",
    "    sent = re.sub('[?|.|!|\\n]', ' ', sentence )\n",
    "    text_list.append(sent)\n",
    "data['text'] = text_list\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758da282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分訓練、測試\n",
    "def k_fold(k, data):\n",
    "    # 2500\n",
    "    sub_size = 2500\n",
    "    # start、end 表示從哪開始切、切到哪\n",
    "    start = k * sub_size\n",
    "    end = start + sub_size\n",
    "    test = data.iloc[start:end]\n",
    "    train_1 = data.iloc[:start]\n",
    "    train_2 = data.iloc[end:len(data)]\n",
    "    train = pd.concat( [train_1, train_2], axis=0, ignore_index=True )\n",
    "    \n",
    "    test_X = test['text']\n",
    "    test_Y = test['stars']\n",
    "    train_X = train['text']\n",
    "    train_Y = train['stars']\n",
    "    # 回傳的資料型態皆被轉成 Series\n",
    "    return train_X, train_Y, test_X, test_Y\n",
    "\n",
    "# 文字轉為詞向量\n",
    "def trans_word_vec(X):\n",
    "    model = Word2Vec.load(\"w2v.model\")\n",
    "    rev_vec_list = np.zeros(400, dtype = float)\n",
    "    for comment in X:\n",
    "        vectors_list = []\n",
    "        sum_list = np.zeros(400, dtype = float)\n",
    "        # 將一篇評論裡每個詞的詞向量存到 vectors_list\n",
    "        # 避免遇到 error，將一篇評論跑完才平均向量\n",
    "        for word in comment:\n",
    "            try:\n",
    "                word_vec = model.wv[word]\n",
    "                vectors_list.append(word_vec)\n",
    "            except KeyError:\n",
    "                continue\n",
    "        # sum_list 會是 1*400 的陣列，代表一篇評論的向量\n",
    "        for i in range( len(vectors_list) ):\n",
    "            temp = vectors_list[i].copy()\n",
    "            sum_list += temp\n",
    "        if (len(vectors_list) != 0):\n",
    "            sum_list /= len(vectors_list)\n",
    "        # 每次算完一篇評論向量，將其加到 rev_vec_list。最後丟掉隨機森林預測 Y\n",
    "        rev_vec_list = np.vstack( (rev_vec_list, sum_list ))\n",
    "\n",
    "    rev_vec_list = np.delete(rev_vec_list, 0, axis=0)\n",
    "    # X_vec = pd.DataFrame(rev_vec_list)\n",
    "    return rev_vec_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f245a7bf",
   "metadata": {},
   "source": [
    "<font size=5> Tf-Idf </font>\n",
    "\n",
    "<font size=3> \n",
    " 隨機森林主要可調整的參數為 max_features、n_estimators、min_sample_leaf <br/>\n",
    " max_features : 單一決策樹使用的最大特徵數量。分為 \"None\"、\"sqrt\"(最大特徵數開根號)、\"比例\"(如 0.2表示使用 20%) <br/>\n",
    " n_estimators : 子樹數量。在電腦可承受的範圍，越多越好 <br/>\n",
    " min_sample_leaf : leaf (決策樹的末端節點) 包含的樣本數。太低會overfit <br/>\n",
    " 超參數之實驗結果在最後\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9548a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tf -Idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# 有 28880個字，找出現最多的 15000 個\n",
    "tv = TfidfVectorizer(stop_words='english', max_features = 15000)\n",
    "# sub_size = 2500\n",
    "avg_acc = 0\n",
    "k = 4\n",
    "sub_size = int(len(data) / k)\n",
    "for i in range(k):\n",
    "    # 分割完train、test後, 跑 tf - idf 模型\n",
    "    train_X, train_Y, test_X, test_Y = k_fold(i, data)\n",
    "    train_X = tv.fit_transform(train_X)\n",
    "    test_X = tv.transform(test_X)\n",
    "    # 使用隨機森林預測結果\n",
    "    forest = RandomForestClassifier(max_features='sqrt', random_state=36)\n",
    "    forest.fit(train_X, train_Y)\n",
    "    pred_Y = forest.predict(test_X)\n",
    "    acc = forest.score(test_X, test_Y)\n",
    "    avg_acc += acc\n",
    "    print( '{} th, accuracy is {}'.format(i+1, acc) )\n",
    "\n",
    "print('Average accuracy is ', round(avg_acc/k, 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2449bdfa",
   "metadata": {},
   "source": [
    "<font size=5> Word2Vec </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37fbcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "stopwords = vectorizer.get_stop_words()\n",
    "# 將評論 split 之後，再把非停頓詞 join。得到去除停頓詞後的評論\n",
    "data['text'] = data['text'].apply(lambda x: ' '.join( [word for word in x.split(' ') if word not in stopwords] ))\n",
    "train_X, train_Y, test_X, test_Y = k_fold(0, data)\n",
    "model = Word2Vec(sentences=train_X, vector_size=400, window=5, min_count=2, epochs=10, workers=3)\n",
    "model.save(\"w2v.model\")\n",
    "train_X_vec = trans_word_vec(train_X)\n",
    "test_X_vec = trans_word_vec(test_X)\n",
    "\n",
    "forest = RandomForestClassifier(max_features='sqrt', random_state=36)\n",
    "forest.fit(train_X_vec, train_Y)\n",
    "pred_Y = forest.predict(test_X_vec)\n",
    "acc = forest.score(test_X_vec, test_Y)\n",
    "print(' 準確率是 ', acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f385697d",
   "metadata": {},
   "source": [
    "<font size=5> Hyperparameter </font>\n",
    "\n",
    "<font size=3>\n",
    " random_state = [20, 25, 29, 30, 36, 39, 49, 50, 55, 66, 69]。55 is the best <br/>\n",
    " min_sample_leaf = [1, 5, 10, 20, 30, 50, 75, 100]。1 is the best, also is default <br/>\n",
    " criterion : 'entropy'(0.795) 略好於 'gini'(0.792)。多 0.003，每個 fold 的結果也比較 tight\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
