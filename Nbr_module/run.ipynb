{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from models import *\n",
    "from review_dataset import ReviewDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, ndcg_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "args = {\n",
    "    'device' : device,\n",
    "    'epochCount':50,\n",
    "    'batch_size': 64,\n",
    "    'ini_rev_dim': 768,\n",
    "    'emb_dim': 512, \n",
    "    'num_heads': 1,\n",
    "    'train_threshold': 0.6,\n",
    "    'test_threshold': 0.7\n",
    "    }\n",
    "\n",
    "train_dataset = ReviewDataset(target='train')\n",
    "train_loader = DataLoader(train_dataset, batch_size=args[\"batch_size\"], shuffle=True)\n",
    "test_dataset = ReviewDataset(target='test')\n",
    "test_loader = DataLoader(test_dataset, batch_size=args[\"batch_size\"], shuffle=True)\n",
    "\n",
    "# Initialize Model\n",
    "ini_rev_dim, emb_dim, num_heads = args['ini_rev_dim'], args['emb_dim'], args['num_heads']\n",
    "nbr_module = Integrated_Neighbor_module(ini_rev_dim=ini_rev_dim, emb_dim=emb_dim, num_heads=num_heads).to(device)\n",
    "\n",
    "# Loss criteria\n",
    "criterion = nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.Adam(nbr_module.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [27:57<00:00, 33.54s/it, result=loss: 0.56552, acc: 0.750,    precision: 0.835, recall: 0.794, f1: 0.812]\n"
     ]
    }
   ],
   "source": [
    "pbar = trange(args['epochCount'])\n",
    "train_loss_list, train_acc_list, train_precision_list, train_recall_list, train_f1_list = [], [], [], [], []\n",
    "test_loss_list, test_acc_list, test_precision_list = [], [], []\n",
    "for epoch in pbar:\n",
    "    \n",
    "    nbr_module.train()\n",
    "    train_loss, train_acc, train_precision, train_recall, train_f1 = [], [], [], [], []\n",
    "    train_precision, train_recall = [], []\n",
    "    # batches_pbar = tqdm(train_loader, desc='Training...', colour='blue',leave=False)\n",
    "    for batch in train_loader:\n",
    "        user_data, item_data, _, y = batch\n",
    "        y = y.to(device)\n",
    "        user_emb, user_itemEmb = user_data['user_emb'], user_data['user_itemEmb']\n",
    "        user_revEmb, user_nbr_revEmb = user_data['user_revEmb'], user_data['user_nbr_revEmb']\n",
    "\n",
    "        item_emb, item_userEmb = item_data['item_emb'], item_data['item_userEmb']\n",
    "        item_revEmb, item_nbr_revEmb = item_data['item_revEmb'], item_data['item_nbr_revEmb']\n",
    "        \n",
    "        output_logits = nbr_module(user_emb.to(device), user_itemEmb.to(device), user_nbr_revEmb.to(device),\n",
    "                                user_revEmb.to(device), item_revEmb.to(device), item_emb.to(device),\n",
    "                                item_nbr_revEmb.to(device), item_userEmb.to(device) )\n",
    "        \n",
    "        # train model\n",
    "        loss = criterion( torch.squeeze(output_logits, dim=1), y.float() )\n",
    "        # Gradients stored in the parameters in the previous step should be cleared out first\n",
    "        optimizer.zero_grad()\n",
    "        # Compute the gradients for parameters\n",
    "        loss.backward()\n",
    "        # grad_norm = nn.utils.clip_grad_norm_(nbr_module.parameters(), max_norm=10)  試試有無影響\n",
    "        # Update the parameters with computed gradients\n",
    "        optimizer.step()\n",
    "        result_logits = torch.where( output_logits > args['train_threshold'], 1, 0 ).squeeze(dim=1)\n",
    "\n",
    "        acc = (result_logits == y).float().mean()\n",
    "        precision = precision_score(y.cpu(), result_logits.cpu(), zero_division=0)\n",
    "        recall = recall_score(y.cpu(), result_logits.cpu(), zero_division=0)\n",
    "        f1 = f1_score(y.cpu(), result_logits.cpu(), zero_division=0)\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "        train_acc.append(acc.cpu())\n",
    "        train_precision.append(precision)\n",
    "        train_recall.append(recall)\n",
    "        train_f1.append(f1)\n",
    "\n",
    "    train_loss_list.append( np.mean(train_loss) )\n",
    "    train_acc_list.append( np.mean(train_acc) )\n",
    "    train_precision_list.append( np.mean(train_precision) )\n",
    "    train_recall_list.append( np.mean(train_recall) )\n",
    "    train_f1_list.append( np.mean(train_f1) )\n",
    "\n",
    "    # train result\n",
    "    # print(f\"Train | loss = {train_t_loss:.5f}, acc = {train_t_acc:.4f}, precision = {train_t_precision:.4f}, recall = {train_t_recall:.4f}, f1 = {train_t_f1}\")\n",
    "\n",
    "    # ---------- Validation ----------\n",
    "    nbr_module.eval()\n",
    "    test_loss, test_acc, test_f1 = [], [], []\n",
    "    test_precision, test_recall = [], []\n",
    "    for batch in test_loader:\n",
    "        user_data, item_data, _, y = batch\n",
    "        y = y.to(device)\n",
    "        user_emb, user_itemEmb = user_data['user_emb'], user_data['user_itemEmb']\n",
    "        user_revEmb, user_nbr_revEmb = user_data['user_revEmb'], user_data['user_nbr_revEmb']\n",
    "\n",
    "        item_emb, item_userEmb = item_data['item_emb'], item_data['item_userEmb']\n",
    "        item_revEmb, item_nbr_revEmb = item_data['item_revEmb'], item_data['item_nbr_revEmb']\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output_logits = nbr_module(user_emb.to(device), user_itemEmb.to(device), user_nbr_revEmb.to(device),\n",
    "                                    user_revEmb.to(device), item_revEmb.to(device), item_emb.to(device),\n",
    "                                    item_nbr_revEmb.to(device), item_userEmb.to(device) )\n",
    "            \n",
    "            loss = criterion( torch.squeeze(output_logits, dim=1), y.float() )\n",
    "            result_logits = torch.where( output_logits > args['test_threshold'], 1, 0 ).squeeze(dim=1)\n",
    "\n",
    "            acc = (result_logits == y).float().mean()\n",
    "            precision = precision_score(y.cpu(), result_logits.cpu(), zero_division=0)\n",
    "            recall = recall_score(y.cpu(), result_logits.cpu(), zero_division=0)\n",
    "            f1 = f1_score(y.cpu(), result_logits.cpu(), zero_division=0)\n",
    "\n",
    "            test_loss.append(loss.item())\n",
    "            test_acc.append(acc.cpu())\n",
    "            test_precision.append(precision)\n",
    "            test_recall.append(recall)\n",
    "            test_f1.append(f1)\n",
    "    \n",
    "    test_loss_list.append(np.mean(test_loss))\n",
    "    test_acc_list.append(np.mean(test_acc))\n",
    "    test_precision_list.append(np.mean(test_precision))\n",
    "    pbar.set_postfix( result= f\"loss: {np.mean(test_loss):.5f}, acc: {np.mean(test_acc):.3f},\\\n",
    "    precision: {np.mean(test_precision):.3f}, recall: {np.mean(test_recall):.3f}, f1: {np.mean(test_f1):.3f}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>type</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Note</th>\n",
       "      <th>Problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td>train</td>\n",
       "      <td>64</td>\n",
       "      <td>0.345558</td>\n",
       "      <td>0.840221</td>\n",
       "      <td>0.892363</td>\n",
       "      <td>0.876115</td>\n",
       "      <td>0.882569</td>\n",
       "      <td>neg_sample, BCE_Loss, lr4, 2 FC(Tanh)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50</td>\n",
       "      <td>train</td>\n",
       "      <td>64</td>\n",
       "      <td>0.711222</td>\n",
       "      <td>0.886682</td>\n",
       "      <td>0.906094</td>\n",
       "      <td>0.96097</td>\n",
       "      <td>0.93198</td>\n",
       "      <td>BCE_w, lr4, 2 FC(Tanh)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50</td>\n",
       "      <td>train</td>\n",
       "      <td>64</td>\n",
       "      <td>0.300555</td>\n",
       "      <td>0.86221</td>\n",
       "      <td>0.907771</td>\n",
       "      <td>0.925411</td>\n",
       "      <td>0.915484</td>\n",
       "      <td>BCE_Loss, lr4, 2 FC(Tanh)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>train</td>\n",
       "      <td>64</td>\n",
       "      <td>0.528859</td>\n",
       "      <td>0.857003</td>\n",
       "      <td>0.880499</td>\n",
       "      <td>0.919345</td>\n",
       "      <td>0.898181</td>\n",
       "      <td>neg_sample, BCE_w, lr4, 2 FC(Tanh)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50</td>\n",
       "      <td>train</td>\n",
       "      <td>64</td>\n",
       "      <td>0.347047</td>\n",
       "      <td>0.839402</td>\n",
       "      <td>0.89133</td>\n",
       "      <td>0.87593</td>\n",
       "      <td>0.881962</td>\n",
       "      <td>neg_sample, BCE_Loss, lr4, 2 FC(Tanh)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch   type batch_size      Loss       Acc Precision    Recall        F1  \\\n",
       "6     50  train         64  0.345558  0.840221  0.892363  0.876115  0.882569   \n",
       "7     50  train         64  0.711222  0.886682  0.906094   0.96097   0.93198   \n",
       "8     50  train         64  0.300555   0.86221  0.907771  0.925411  0.915484   \n",
       "9     50  train         64  0.528859  0.857003  0.880499  0.919345  0.898181   \n",
       "10    50  train         64  0.347047  0.839402   0.89133   0.87593  0.881962   \n",
       "\n",
       "                                     Note Problem  \n",
       "6   neg_sample, BCE_Loss, lr4, 2 FC(Tanh)     NaN  \n",
       "7                  BCE_w, lr4, 2 FC(Tanh)     NaN  \n",
       "8               BCE_Loss, lr4, 2 FC(Tanh)     NaN  \n",
       "9      neg_sample, BCE_w, lr4, 2 FC(Tanh)     NaN  \n",
       "10  neg_sample, BCE_Loss, lr4, 2 FC(Tanh)          "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 結果寫入 excel\n",
    "note = 'neg_sample, BCE_Loss, lr4, 2 FC(Tanh)'\n",
    "problem = ''\n",
    "res_df = pd.read_csv('result_plot/results.csv')\n",
    "# result\n",
    "train_res = [args['epochCount'], 'train', args['batch_size'], np.mean(train_loss_list[-10:]), np.mean(train_acc_list[-10:]),\n",
    "             np.mean(train_precision_list[-10:]), np.mean(train_recall_list[-10:]), np.mean(train_f1_list[-10:]), note, problem ]\n",
    "temp = pd.DataFrame(train_res).T\n",
    "temp.columns = ['epoch', 'type', 'batch_size', 'Loss', 'Acc', 'Precision', 'Recall', 'F1', 'Note', 'Problem']\n",
    "res_df = pd.concat([res_df, temp], axis=0, ignore_index=True)\n",
    "res_df.to_csv('result_plot/results.csv', index=False)\n",
    "res_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_curve(train_loss, plot_name, f_name):\n",
    "    plt.plot(train_loss, color=\"blue\", label=\"Train\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title(plot_name)\n",
    "    plt.savefig(f'result_plot/excel_plot/{f_name}.png')\n",
    "    plt.show()\n",
    "\n",
    "idx = len(res_df) + 1\n",
    "draw_curve(train_loss_list, 'Train Loss_batch'+str(args['batch_size']), str(idx)+'_train_loss')\n",
    "draw_curve(train_acc_list, 'Train Acc_batch'+str(args['batch_size']), str(idx)+'_train_acc')\n",
    "draw_curve(test_loss_list, 'Test Loss_batch'+str(args['batch_size']), str(idx)+'_test_loss')\n",
    "draw_curve(test_acc_list, 'Test Acc_batch'+str(args['batch_size']), str(idx)+'_test_acc')\n",
    "draw_curve(test_precision_list, 'Test Pre_batch'+str(args['batch_size']), str(idx)+'_test_pre')\n",
    "# torch.save(nbr_module.state_dict(), 'model/parameters/nbr_module_lr4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
